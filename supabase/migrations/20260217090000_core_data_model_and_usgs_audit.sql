-- Core backend data model for deterministic USGS ingestion and auditability.
-- Non-destructive: adds new tables/views/functions and keeps legacy tables intact.

create extension if not exists pgcrypto;

alter table if exists public.rivers add column if not exists river_name text;
alter table if exists public.rivers add column if not exists gauge_label text;

-- 1) Core daily table (one row per river per observation date)
create table if not exists public.river_daily (
  id bigint generated by default as identity primary key,
  river_id uuid not null references public.rivers(id) on delete cascade,
  obs_date date not null,
  source text not null default 'usgs_iv',

  -- normalized measurements
  flow_cfs numeric,
  water_temp_f numeric,
  gage_height_ft numeric,
  wind_am_mph numeric,
  wind_pm_mph numeric,

  -- derived metrics
  median_flow_cfs numeric,
  flow_ratio numeric,
  change_48h_pct numeric,

  -- optional scoring fields (can be filled by existing scoring jobs)
  fishability_score numeric,
  bite_tier text,

  -- source traceability
  source_flow_observed_at timestamptz,
  source_temp_observed_at timestamptz,
  source_gage_observed_at timestamptz,
  source_parameter_codes text[] not null default '{}',
  source_payload jsonb,

  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

create index if not exists idx_river_daily_obs_date on public.river_daily (obs_date desc);
create index if not exists idx_river_daily_river_date on public.river_daily (river_id, obs_date desc);
create unique index if not exists idx_river_daily_river_obs_date on public.river_daily (river_id, obs_date);

create or replace function public._touch_river_daily_updated_at()
returns trigger
language plpgsql
as $$
begin
  new.updated_at := now();
  return new;
end;
$$;

drop trigger if exists trg_touch_river_daily on public.river_daily;
create trigger trg_touch_river_daily
before update on public.river_daily
for each row execute procedure public._touch_river_daily_updated_at();

-- 2) Ingestion audit logs
create table if not exists public.usgs_pull_runs (
  id uuid primary key default gen_random_uuid(),
  started_at timestamptz not null default now(),
  finished_at timestamptz,
  cadence text not null default 'manual',
  status text not null default 'running', -- running | success | partial | failed
  sites_total integer not null default 0,
  sites_ok integer not null default 0,
  sites_failed integer not null default 0,
  error_message text,
  created_at timestamptz not null default now()
);

create table if not exists public.usgs_pull_sites (
  id bigint generated by default as identity primary key,
  run_id uuid not null references public.usgs_pull_runs(id) on delete cascade,
  river_id uuid references public.rivers(id) on delete set null,
  usgs_site_no text not null,
  obs_date date not null,
  status text not null, -- success | failed | skipped
  error_message text,
  http_status integer,

  flow_cfs numeric,
  water_temp_f numeric,
  gage_height_ft numeric,
  source_flow_observed_at timestamptz,
  source_temp_observed_at timestamptz,
  source_gage_observed_at timestamptz,
  parameter_codes text[] not null default '{}',
  raw_summary jsonb,

  created_at timestamptz not null default now()
);

create index if not exists idx_usgs_pull_sites_run on public.usgs_pull_sites (run_id, id desc);
create index if not exists idx_usgs_pull_sites_river_date on public.usgs_pull_sites (river_id, obs_date desc);
create index if not exists idx_usgs_pull_runs_started_at on public.usgs_pull_runs (started_at desc);

-- 3) RLS read policies (safe for app-side validation and dashboarding)
alter table public.river_daily enable row level security;
alter table public.usgs_pull_runs enable row level security;
alter table public.usgs_pull_sites enable row level security;

drop policy if exists "Allow public read river_daily" on public.river_daily;
create policy "Allow public read river_daily"
  on public.river_daily for select
  using (true);

drop policy if exists "Allow public read usgs_pull_runs" on public.usgs_pull_runs;
create policy "Allow public read usgs_pull_runs"
  on public.usgs_pull_runs for select
  using (true);

drop policy if exists "Allow public read usgs_pull_sites" on public.usgs_pull_sites;
create policy "Allow public read usgs_pull_sites"
  on public.usgs_pull_sites for select
  using (true);

-- 4) Derived metric refresh (median flow, ratio, 48h change)
create or replace function public.refresh_river_daily_metrics(
  p_river_id uuid default null,
  p_obs_date date default null
)
returns void
language plpgsql
security definer
set search_path = public
as $$
begin
  update public.river_daily d
  set
    median_flow_cfs = stats.median_flow,
    flow_ratio = case
      when stats.median_flow is null or stats.median_flow = 0 or d.flow_cfs is null then null
      else round((d.flow_cfs / stats.median_flow)::numeric, 4)
    end,
    change_48h_pct = case
      when lag_2.flow_cfs is null or lag_2.flow_cfs = 0 or d.flow_cfs is null then null
      else round((((d.flow_cfs - lag_2.flow_cfs) / lag_2.flow_cfs) * 100.0)::numeric, 2)
    end
  from lateral (
    select
      percentile_cont(0.5) within group (order by d_hist.flow_cfs) as median_flow
    from public.river_daily d_hist
    where d_hist.river_id = d.river_id
      and d_hist.flow_cfs is not null
      and d_hist.obs_date >= d.obs_date - 180
      and d_hist.obs_date < d.obs_date
  ) stats
  left join public.river_daily lag_2
    on lag_2.river_id = d.river_id
   and lag_2.obs_date = d.obs_date - 2
  where (p_river_id is null or d.river_id = p_river_id)
    and (p_obs_date is null or d.obs_date = p_obs_date);
end;
$$;

grant execute on function public.refresh_river_daily_metrics(uuid, date) to anon, authenticated, service_role;

-- 5) API views for frontend + audit
create or replace view public.v_river_latest as
with latest_daily as (
  select distinct on (d.river_id)
    d.river_id,
    d.obs_date,
    d.flow_cfs,
    d.water_temp_f,
    d.gage_height_ft,
    d.wind_am_mph,
    d.wind_pm_mph,
    d.median_flow_cfs,
    d.flow_ratio,
    d.change_48h_pct,
    d.fishability_score,
    d.bite_tier,
    d.source_flow_observed_at,
    d.source_temp_observed_at,
    d.source_parameter_codes,
    d.updated_at
  from public.river_daily d
  order by d.river_id, d.obs_date desc
),
legacy_scores as (
  select distinct on (coalesce(r.id::text, s.river_id::text))
    r.id as river_id,
    s.date,
    s.fishability_score_calc,
    s.bite_tier
  from public.river_daily_scores s
  left join public.rivers r
    on r.id::text = s.river_id::text
    or r.slug = s.river_id::text
    or r.river = s.river
  order by coalesce(r.id::text, s.river_id::text), s.date desc
)
select
  r.id as river_id,
  r.slug,
  coalesce(r.river_name, r.river, r.slug) as river_name,
  r.gauge_label,
  r.usgs_site_no,
  r.latitude,
  r.longitude,
  ld.obs_date as date,
  ld.flow_cfs,
  ld.water_temp_f,
  ld.wind_am_mph,
  ld.wind_pm_mph,
  ld.median_flow_cfs,
  ld.flow_ratio as flow_ratio_calc,
  ld.change_48h_pct as change_48h_pct_calc,
  coalesce(ld.fishability_score, ls.fishability_score_calc) as fishability_score_calc,
  coalesce(ld.bite_tier, ls.bite_tier) as bite_tier,
  ld.source_flow_observed_at,
  ld.source_temp_observed_at,
  ld.source_parameter_codes,
  ld.updated_at
from public.rivers r
left join latest_daily ld on ld.river_id = r.id
left join legacy_scores ls on ls.river_id = r.id
where r.is_active = true;

create or replace view public.v_river_detail as
select
  v.*,
  case
    when v.fishability_score_calc is null then null
    when v.fishability_score_calc >= 85 then 'Excellent'
    when v.fishability_score_calc >= 70 then 'Good'
    when v.fishability_score_calc >= 55 then 'Fair'
    else 'Tough'
  end as bite_tier_label
from public.v_river_latest v;

create or replace view public.v_river_health as
select
  v.river_id,
  v.slug,
  v.river_name,
  v.usgs_site_no,
  v.date,
  v.flow_cfs,
  v.water_temp_f,
  v.median_flow_cfs,
  v.change_48h_pct_calc,
  v.source_flow_observed_at,
  (v.source_flow_observed_at is null or v.source_flow_observed_at < now() - interval '36 hours') as is_stale,
  (v.water_temp_f is null) as missing_temperature,
  (v.median_flow_cfs is null) as missing_median_baseline,
  (abs(coalesce(v.change_48h_pct_calc, 0)) >= 80) as possible_spike
from public.v_river_latest v;

create or replace view public.v_usgs_pull_log as
select
  r.id as run_id,
  r.started_at,
  r.finished_at,
  r.cadence,
  r.status,
  r.sites_total,
  r.sites_ok,
  r.sites_failed,
  s.id as site_log_id,
  s.river_id,
  rv.slug,
  coalesce(rv.river_name, rv.river, rv.slug) as river_name,
  s.usgs_site_no,
  s.obs_date,
  s.status as site_status,
  s.error_message as site_error,
  s.http_status,
  s.flow_cfs,
  s.water_temp_f,
  s.source_flow_observed_at,
  s.source_temp_observed_at,
  s.parameter_codes,
  s.created_at as site_logged_at
from public.usgs_pull_runs r
left join public.usgs_pull_sites s on s.run_id = r.id
left join public.rivers rv on rv.id = s.river_id
order by r.started_at desc, s.id desc;

-- 6) Lightweight history RPC for UI mini-charts
create or replace function public.river_history_14d(p_river_id uuid)
returns table (
  obs_date date,
  flow_cfs numeric,
  water_temp_f numeric,
  fishability_score numeric
)
language sql
security definer
set search_path = public
as $$
  select
    d.obs_date,
    d.flow_cfs,
    d.water_temp_f,
    coalesce(d.fishability_score, s.fishability_score_calc) as fishability_score
  from public.river_daily d
  left join public.river_daily_scores s
    on (s.river_id::text = p_river_id::text or s.river_id::text = (select slug from public.rivers where id = p_river_id))
   and s.date = d.obs_date
  where d.river_id = p_river_id
  order by d.obs_date desc
  limit 14;
$$;

grant execute on function public.river_history_14d(uuid) to anon, authenticated, service_role;

grant select on public.v_river_latest to anon, authenticated;
grant select on public.v_river_detail to anon, authenticated;
grant select on public.v_river_health to anon, authenticated;
grant select on public.v_usgs_pull_log to anon, authenticated;

comment on table public.river_daily is 'Core normalized daily facts for each river. Legacy score tables remain for compatibility.';
comment on table public.usgs_pull_runs is 'Ingestion run-level audit log for USGS pulls.';
comment on table public.usgs_pull_sites is 'Per-site success/failure logs and source timestamps for USGS ingestion runs.';
